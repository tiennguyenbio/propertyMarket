# Daily Dev Log â€” 2025-12-11

## What I did
- Use Playwright to get the list of suburbs (14775 records), saved as "auspost_suburbs.csv". Create AusPost url: https://auspost.com.au + /postcode/suburb.
- Use Playwright to get all postcodes from the list of AusPost url. It took 6 hrs running. 
- Clean and process the postcode data: Remove duplicates. Split "suburb", "state", "postcode" into separate columns. Convert suburb and state data to lowercase. Replace the whitespace by "-" for postcode. 
- Create real estate website url: base_url + /state/postcode.
- Use Playwright's "locator" with content_text(), successfully retrieve all text and number from 1 page. 
- Try to scrape data from the line chart with tooltips showing detailed values of each year. Use Element Inspector console to export text, however it works for only 1 visible tooltip.

## What I learned
- Playwright: use different agent (browsers, OS) and wait time to avoid bot detection.
- Save postcode data to csv file every 50 records to minimize data loss in case of unexpected termination happend (detected and blocked by the system, internet disconnection, hardward problem).
- Use cmd + \ to freeze the tooltips screen (debbuger enabling).
- Use Playwright's "locator".
- The existence of visible and invisible items.

## Problems / Bugs
- run uv sync the repo => cannot fully sync the packages
- run uv pip install e . => incompatible python 12
- install python 12 by downloading file from website => installed successfully, check python --version in terminal showed "python 11.13".
- run "uv sync" failed.

## Next steps / Ideas
- Double check installation of python 12.0
- Moving code to repo and push to github.
- Research what "uv sync" does.

## Notes / Code snippets